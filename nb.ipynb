{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from google.generativeai import caching\n",
    "import datetime\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['ANTHROPIC_API_KEY'] = \"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\"\n",
    "os.environ['GOOGLE_API_KEY'] = \"AIzaSyAd49exGQku8GONoN18gDjTTkzLYuaBKZY\"\n",
    "genai.configure(api_key=os.environ['GOOGLE_API_KEY'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_video_file = 'v1.mp4'\n",
    "\n",
    "video_file = genai.upload_file(path=path_to_video_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for video to be processed.\n",
      "Waiting for video to be processed.\n",
      "Video processing complete: https://generativelanguage.googleapis.com/v1beta/files/5ug2lytp90p8\n"
     ]
    }
   ],
   "source": [
    "# Wait for the file to finish processing\n",
    "while video_file.state.name == 'PROCESSING':\n",
    "  print('Waiting for video to be processed.')\n",
    "  time.sleep(2)\n",
    "  video_file = genai.get_file(video_file.name)\n",
    "\n",
    "print(f'Video processing complete: {video_file.uri}')\n",
    "\n",
    "# Create a cache with a 5 minute TTL\n",
    "cache = caching.CachedContent.create(\n",
    "    model='models/gemini-1.5-flash-001',\n",
    "    display_name='movie', # used to identify the cache\n",
    "    system_instruction=(\n",
    "        'You are an expert video analyzer, and your job is to answer '\n",
    "        'the user\\'s query based on the video file you have access to.'\n",
    "    ),\n",
    "    contents=[video_file],\n",
    "    ttl=datetime.timedelta(minutes=5),\n",
    ")\n",
    "\n",
    "# Construct a GenerativeModel which uses the created cache.\n",
    "model = genai.GenerativeModel.from_cached_content(cached_content=cache)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making LLM inference request...\n",
      "[00:00:01] Matin Khajavi: Hey, Matin, what’s up?\n",
      "[00:00:03] matin rahimani: What’s up, man? How you doing?\n",
      "[00:00:05] Matin Khajavi: Good, good. How are you?\n",
      "[00:00:07] matin rahimani: Not bad.\n",
      "[00:00:09] Matin Khajavi: Alright. So,\n",
      "[00:00:10] matin rahimani: What's going on?\n",
      "[00:00:12] Matin Khajavi: So the reason I called you today was\n",
      "[00:00:13] matin rahimani: Tell me about it.\n",
      "[00:00:17] Matin Khajavi: uh, we’re going to have to do a code review\n",
      "[00:00:19] Matin Khajavi: for what you’ve implemented,\n",
      "[00:00:22] Matin Khajavi: and, uh, just talk through it, maybe set a meeting, uh,\n",
      "[00:00:28] Matin Khajavi: tomorrow or day after tomorrow and talk about it.\n",
      "[00:00:34] matin rahimani: Okay. Um [nodding]\n",
      "[00:00:37] Matin Khajavi: Alright, talk to you later.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "I have a transcript for this video.\n",
    "[00:00:01] Matin Khajavi: Hey, Matin, what’s up?\n",
    "[00:00:04] matin rahimani: What’s up, man? How you doing? \n",
    "[00:00:04] Matin Khajavi: Good, good. How are you?\n",
    "[00:00:05] matin rahimani: Not bad.\n",
    "[00:00:09] Matin Khajavi: Alright. So,\n",
    "[00:00:11] Matin Khajavi: So the reason I called you today was\n",
    "[00:00:17] Matin Khajavi: uh, we’re going to have to do a code review\n",
    "[00:00:19] Matin Khajavi: for what you’ve implemented,\n",
    "[00:00:22] Matin Khajavi: and, uh, just talk through it, maybe set a meeting, uh,\n",
    "[00:00:28] Matin Khajavi: tomorrow or day after tomorrow and talk about it.\n",
    "[00:00:34] matin rahimani: Okay. Um\n",
    "[00:00:38] Matin Khajavi: Alright, talk to you later.\n",
    "\n",
    "\n",
    "Go through the transcript and the timestamps. Make sure they are correct. If not, fix them. Also try detecting specific head and hand gestures, such as nodding and shaking, during a video-recorded meeting and add them to the transcript if detected.\n",
    "\"\"\"\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are an expert video analyzer, and your job is to answer\n",
    "the user's query based on the video file you have access to.\n",
    "\n",
    "Just provide the output that has been asked in the prompt and nothing else.\n",
    "\"\"\"\n",
    "\n",
    "# Choose a Gemini model.\n",
    "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro-latest\")\n",
    "\n",
    "# Make the LLM request.\n",
    "print(\"Making LLM inference request...\")\n",
    "response = model.generate_content([system_prompt, prompt, video_file],\n",
    "                                  request_options={\"timeout\": 600}, generation_config=genai.types.GenerationConfig(temperature=0.0))\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the model\n",
    "response = model.generate_content([(\n",
    "    'Introduce different characters in the movie by describing '\n",
    "    'their personality, looks, and names. Also list the timestamps '\n",
    "    'they were introduced for the first time.')])\n",
    "\n",
    "print(response.usage_metadata)\n",
    "\n",
    "# The output should look something like this:\n",
    "#\n",
    "# prompt_token_count: 696219\n",
    "# cached_content_token_count: 696190\n",
    "# candidates_token_count: 214\n",
    "# total_token_count: 696433\n",
    "\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
