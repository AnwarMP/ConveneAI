This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2024-11-03T02:38:59.780Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repomix, visit: https://github.com/yamadashy/repomix

================================================================
Repository Structure
================================================================
backend/
  app/
    __init__.py
    routes.py
  config/
    __init__.py
  __init__.py
  .gitignore
  run.py
src/
  services/
    __init__.py
    email_service.py
  utils/
    __init__.py
    context_provider.py
    query_generator.py
  __init__.py
  agent.py
.gitignore
README.md
requirements.txt
setup.py

================================================================
Repository Files
================================================================

================
File: backend/app/__init__.py
================
from flask import Flask
from config import Config
from asgiref.wsgi import WsgiToAsgi

def create_app():
    app = Flask(__name__)
    app.config.from_object(Config)

    # Register blueprints
    from app.routes import main
    app.register_blueprint(main)

    # Wrap with ASGI for async support
    asgi_app = WsgiToAsgi(app)
    return asgi_app, app

================
File: backend/app/routes.py
================
from flask import Blueprint, request, jsonify
from src.agent import EmailQueryAgent
from config import Config

main = Blueprint('main', __name__)

# Initialize with OpenAI
email_agent = EmailQueryAgent(
    llm_provider="openai",
    api_key=Config.OPENAI_API_KEY
)

@main.route('/health', methods=['GET'])
def health_check():
    return jsonify({'status': 'healthy'}), 200

@main.route('/analyze-transcript', methods=['POST'])
async def analyze_transcript():
    """
    Endpoint to analyze transcript segments for email references
    
    Expected JSON payload:
    {
        "transcript": "string of meeting transcript"
    }
    
    Returns:
    {
        "status": "success",
        "results": {
            "analysis": {
                "context": "Why these queries were generated",
                "queries": ["list", "of", "gmail", "queries"],
                "extracted_info": {
                    "sender": "sender name",
                    "recipients": ["recipient names"],
                    "subject": "subject line",
                    "date_range": {"after": "date", "before": "date"},
                    "attachment_type": "file type"
                }
            },
            "confidence": 0.8
        }
    }
    """
    try:
        data = request.get_json()
        if not data or 'transcript' not in data:
            return jsonify({
                'error': 'No transcript provided',
                'example_payload': {
                    'transcript': """
                    John: Can you find that budget email from Sarah?
                    Mary: The one from last week with the Excel file?
                    John: Yes, that's the one!
                    """
                }
            }), 400
        
        transcript = data['transcript']
        analysis_results = await email_agent.analyze_transcript_segment(transcript)
        
        return jsonify({
            'status': 'success',
            'results': analysis_results,
        }), 200
    
    except Exception as e:
        return jsonify({
            'error': str(e),
            'status': 'error'
        }), 500

@main.route('/demo-queries', methods=['GET'])
async def demo_queries():
    """Demo endpoint with sample transcripts and their analysis"""
    
    sample_transcripts = [
        {
            "scenario": "Budget Review Email",
            "transcript": """
            John: Hey team, can someone forward me that email Sarah sent last week about the Q4 budget review?
            Mary: The one with the Excel spreadsheet attachments?
            John: Yeah, the one she sent to the whole finance team on Thursday.
            Bob: I think it had 'FY24 Q4 Budget Final' in the subject line.
            """
        },
        {
            "scenario": "Marketing Campaign PDF",
            "transcript": """
            Alice: Has anyone seen the marketing presentation Janet sent yesterday?
            Bob: Was it the PDF with the new campaign designs?
            Alice: Yes, she sent it to the marketing team with all the Q1 plans.
            """
        },
        {
            "scenario": "Project Timeline",
            "transcript": """
            Mike: Could you find that email thread from David about project timelines?
            Sarah: The one from last month with the Gantt chart attached?
            Mike: Yes, he sent it to all project managers with subject 'Updated 2024 Roadmap'
            """
        }
    ]
    
    try:
        results = []
        for sample in sample_transcripts:
            analysis = await email_agent.analyze_transcript_segment(sample["transcript"])
            results.append({
                "scenario": sample["scenario"],
                "transcript": sample["transcript"],
                "analysis": analysis
            })
        
        return jsonify({
            'status': 'success',
            'sample_analyses': results
        }), 200
    
    except Exception as e:
        return jsonify({
            'error': str(e),
            'status': 'error'
        }), 500
    
@main.route('/test-email', methods=['GET'])
async def test_email():
    """Simple test endpoint for Gmail integration"""
    try:
        transcript = "Can you find the email from Anwar?"
        
        analysis_results = await email_agent.analyze_transcript_segment(transcript)
        
        return jsonify({
            'status': 'success',
            'transcript': transcript,
            'results': analysis_results
        }), 200
    
    except Exception as e:
        return jsonify({
            'error': str(e),
            'status': 'error'
        }), 500

================
File: backend/config/__init__.py
================
import os
from dotenv import load_dotenv

load_dotenv()

class Config:
    # API Keys
    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
    ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')
    
    # LLM Configuration
    DEFAULT_LLM_PROVIDER = "openai"  # or "anthropic"
    
    # OpenAI specific settings
    OPENAI_MODEL = "gpt-4o-mini"  # GPT-4 Turbo is faster than GPT-4
    OPENAI_TEMPERATURE = 0.1
    
    # Anthropic specific settings
    ANTHROPIC_MODEL = "claude-3-5-sonnet-20241022"


    # Email Configuration
    # Add to Config class:
    GOOGLE_CLIENT_ID = os.getenv('GOOGLE_CLIENT_ID')
    GOOGLE_CLIENT_SECRET = os.getenv('GOOGLE_CLIENT_SECRET')
    GOOGLE_CREDENTIALS_FILE = 'credentials.json'
    GOOGLE_TOKEN_FILE = 'token.json'

================
File: backend/__init__.py
================
"""
Backend package initialization.
This file marks the backend directory as a Python package and can contain package-level configuration.
"""

from pathlib import Path

# Define important paths
BACKEND_ROOT = Path(__file__).parent
PROJECT_ROOT = BACKEND_ROOT.parent

# Version info
__version__ = "0.1.0"

# Package level constants
API_PREFIX = "/api/v1"
DEFAULT_HOST = "0.0.0.0"
DEFAULT_PORT = 5000

# You can add more package-level configuration here

================
File: backend/.gitignore
================
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
env/
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
*.egg-info/
.installed.cfg
*.egg

# Environment variables
.env

# IDE
.idea/
.vscode/
*.swp
*.swo

# OS
.DS_Store

================
File: backend/run.py
================
import os
import sys
from pathlib import Path

# Add project root to Python path
project_root = Path(__file__).parent.parent.absolute()
sys.path.append(str(project_root))

import asyncio
from hypercorn.config import Config
from hypercorn.asyncio import serve
from app import create_app

asgi_app, flask_app = create_app()

if __name__ == '__main__':
    config = Config()
    config.bind = ["0.0.0.0:5000"]
    asyncio.run(serve(asgi_app, config))

================
File: src/services/__init__.py
================
"""
Services package initialization.
Contains service implementations for external integrations.
"""

from .email_service import EmailService

__all__ = ['EmailService']

================
File: src/services/email_service.py
================
from typing import List, Dict
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
import os
from pathlib import Path

class EmailService:
    """Simple Gmail service that returns first matching email"""
    
    SCOPES = ['https://www.googleapis.com/auth/gmail.readonly']
    CREDENTIALS_DIR = Path('.credentials')
    
    def __init__(self):
        # Create credentials directory if it doesn't exist
        self.CREDENTIALS_DIR.mkdir(exist_ok=True)
        self.service = self._get_gmail_service()

    async def search_emails(self, queries: List[str]) -> List[Dict]:
        """Search emails and return first result for each query"""
        results = []
        
        for query in queries:
            try:
                # Search for messages
                response = self.service.users().messages().list(
                    userId='me',
                    q=query,
                    maxResults=1  # Just get the first match
                ).execute()
                
                if 'messages' in response:
                    # Get the first message's details
                    msg_id = response['messages'][0]['id']
                    msg = self.service.users().messages().get(
                        userId='me',
                        id=msg_id,
                        format='metadata',
                        metadataHeaders=['subject', 'from', 'date']
                    ).execute()
                    
                    # Extract headers
                    headers = msg['payload']['headers']
                    subject = next(
                        (h['value'] for h in headers if h['name'].lower() == 'subject'),
                        '(no subject)'
                    )
                    sender = next(
                        (h['value'] for h in headers if h['name'].lower() == 'from'),
                        '(no sender)'
                    )
                    
                    # Create result
                    result = {
                        'id': msg_id,
                        'subject': subject,
                        'from': sender,
                        'url': f"https://mail.google.com/mail/u/0/#inbox/{msg_id}",
                        'query_used': query
                    }
                    
                    results.append(result)
                    
            except Exception as e:
                print(f"Error searching emails: {e}")
                continue
                
        return results

================
File: src/utils/__init__.py
================
"""
Utilities package initialization.
Contains utility classes and helper functions for email analysis and context management.

Classes:
    EmailQueryGenerator: Generates Gmail search queries from analyzed transcripts
    ContextProvider: Provides contextual information like dates and times
"""

from .query_generator import EmailQueryGenerator
from .context_provider import ContextProvider

# Define which classes/functions should be available when using 'from src.utils import *'
__all__ = [
    'EmailQueryGenerator',
    'ContextProvider'
]

# Version tracking
__version__ = '0.1.0'

# Commonly used instances
default_query_generator = EmailQueryGenerator()
context_provider = ContextProvider()

# Helper function for easy access to current context
def get_current_context():
    """Get the current date and time context"""
    return context_provider.get_current_context()

# Export helper functions as well
__all__ += ['get_current_context']

================
File: src/utils/context_provider.py
================
from datetime import datetime, timedelta
from typing import Dict, Optional

class ContextProvider:
    """Provides contextual information for email analysis"""
    
    def __init__(self):
        self.date_keywords = {
            "yesterday": 1,
            "last week": 7,
            "last month": 30,
            "today": 0
        }
    
    def get_current_context(self) -> Dict:
        """Get current date-time context"""
        now = datetime.now()
        return {
            "current_date": now.strftime("%Y/%m/%d"),
            "current_time": now.strftime("%H:%M:%S"),
            "current_day": now.strftime("%A"),
            "yesterday": (now - timedelta(days=1)).strftime("%Y/%m/%d"),
            "last_week": (now - timedelta(days=7)).strftime("%Y/%m/%d"),
            "last_month": (now - timedelta(days=30)).strftime("%Y/%m/%d")
        }

    def parse_date_reference(self, text: str) -> Dict[str, Optional[str]]:
        """Parse relative date references into Gmail date formats"""
        today = datetime.now()
        
        # Check for specific date references
        for keyword, days in self.date_keywords.items():
            if keyword in text.lower():
                if days == 0:  # today
                    date = today
                else:
                    date = today - timedelta(days=days)
                    
                # For ranges like "last week", "last month"
                if keyword in ["last week", "last month"]:
                    return {
                        "after": (date - timedelta(days=7 if keyword == "last week" else 30)).strftime("%Y/%m/%d"),
                        "before": today.strftime("%Y/%m/%d")
                    }
                else:  # for specific days like "yesterday"
                    return {
                        "after": date.strftime("%Y/%m/%d"),
                        "before": (date + timedelta(days=1)).strftime("%Y/%m/%d")
                    }
        
        return {"after": None, "before": None}

    @staticmethod
    def format_date_for_query(date_str: Optional[str]) -> str:
        """Format a date string for Gmail query"""
        try:
            date = datetime.strptime(date_str, "%Y/%m/%d")
            return date.strftime("%Y/%m/%d")
        except (ValueError, TypeError):
            return ""

================
File: src/utils/query_generator.py
================
from typing import List, Dict, Optional
from datetime import datetime, timedelta

class EmailQueryGenerator:
    """Generate Gmail search queries based on transcript context"""
    
    def __init__(self):
        self.date_keywords = {
            "yesterday": 1,
            "last week": 7,
            "last month": 30,
            "today": 0
        }

    def parse_date_reference(self, text: str) -> Dict[str, str]:
        """Parse relative date references into Gmail date formats"""
        today = datetime.now()
        
        # Check for specific date references
        for keyword, days in self.date_keywords.items():
            if keyword in text.lower():
                if days == 0:  # today
                    date = today
                else:
                    date = today - timedelta(days=days)
                    
                # For ranges like "last week", "last month"
                if keyword in ["last week", "last month"]:
                    return {
                        "after": (date - timedelta(days=7 if keyword == "last week" else 30)).strftime("%Y/%m/%d"),
                        "before": today.strftime("%Y/%m/%d")
                    }
                else:  # for specific days like "yesterday"
                    return {
                        "after": date.strftime("%Y/%m/%d"),
                        "before": (date + timedelta(days=1)).strftime("%Y/%m/%d")
                    }
        
        return {"after": None, "before": None}

    def generate_queries(self, analysis_result: Dict) -> List[str]:
        """
        Generate Gmail search queries based on LLM analysis
        
        Args:
            analysis_result: Dict containing:
                - sender: str
                - recipients: List[str]
                - subject: str
                - date_range: Dict[str, str]
                - attachment_type: str
                
        Returns:
            List of Gmail search query strings
        """
        queries = []
        
        # Extract components with safe gets
        sender = analysis_result.get("sender", "")
        recipients = analysis_result.get("recipients", [])
        subject = analysis_result.get("subject", "")
        attachment_type = analysis_result.get("attachment_type", "")
        date_range = analysis_result.get("date_range", {})
        
        # Build base query
        if sender:
            base_query = f"from:{sender}"
            queries.append(base_query)
            
            # Add recipient if available
            if recipients:
                for recipient in recipients:
                    queries.append(f"{base_query} to:{recipient}")
            
            # Add subject if available
            if subject:
                queries.append(f"{base_query} subject:({subject})")
            
            # Add attachment info if available
            if attachment_type:
                queries.append(f"{base_query} has:attachment filename:{attachment_type}")
        
        # Add date constraints
        if date_range:
            date_parts = []
            if date_range.get("after"):
                date_parts.append(f"after:{date_range['after']}")
            if date_range.get("before"):
                date_parts.append(f"before:{date_range['before']}")
            
            if date_parts:
                date_str = " ".join(date_parts)
                # Add dates to existing queries
                new_queries = []
                for query in queries:
                    new_queries.append(f"{query} {date_str}")
                queries.extend(new_queries)
        
        return queries if queries else [""]  # Return empty query if no components found

================
File: src/__init__.py
================
"""
Source package initialization.
This file marks the src directory as a Python package and provides convenient imports
for commonly used components.
"""

from pathlib import Path

# Define important paths
SRC_ROOT = Path(__file__).parent
PROJECT_ROOT = SRC_ROOT.parent

# Version info
__version__ = "0.1.0"

# Import commonly used components for easier access
from .agent import EmailQueryAgent, MeetingAnalysisAgent
from .services.email_service import EmailService
from .utils.query_generator import EmailQueryGenerator

# Define what should be available when someone does 'from src import *'
__all__ = [
    'EmailQueryAgent',
    'MeetingAnalysisAgent',
    'EmailService',
    'EmailQueryGenerator'
]

================
File: src/agent.py
================
import os
from typing import Optional, List, Dict
from llama_index.llms.anthropic import Anthropic
from llama_index.llms.openai import OpenAI
from llama_index.core.agent import FunctionCallingAgent
from llama_index.core.llms import ChatMessage, LLM  # Added LLM import
from llama_index.core.tools import FunctionTool

from src.services.email_service import EmailService

import json
import re
from typing import Dict, Any

from src.utils import *
class MeetingAnalysisAgent:
    def __init__(self, api_key: Optional[str] = None):
        """Initialize the meeting analysis agent"""
        self.api_key = api_key or os.getenv("ANTHROPIC_API_KEY")
        if not self.api_key:    
            raise ValueError("Anthropic API key must be provided")

        self.llm = Anthropic(
            model="claude-3-5-sonnet-20241022",
            api_key=self.api_key
        )
        
        self.agent = self._initialize_agent()

    def _initialize_agent(self) -> FunctionCallingAgent:
        """Initialize the function calling agent with system prompt"""
        prefix_messages = [
            ChatMessage(
                role="system",
                content=(
                    "You are a real-time meeting analysis assistant. Your task is to process "
                    "new meeting transcript segments and update the existing summary. "
                    
                    "You will receive:"
                    "1. The existing summary (if any)"
                    "2. A new transcript segment"
                    
                    "Provide an updated summary that:"
                    "- Incorporates new information with existing points"
                    "- Removes redundancies"
                    "- Updates existing points with new context"
                    "- Maintains clear, concise bullet points"
                    
                    "Format the output into these sections (only when relevant):"
                    "• Summary Points:"
                    "• Action Items:"
                    "• Decisions Made:"
                    "• Questions Raised:"
                    "• Follow-up Required:"
                    
                    "Keep the style consistent and focus on clarity and brevity."
                )
            )
        ]
        
        return FunctionCallingAgent.from_tools(
            tools=[],  # Tools will be added later
            llm=self.llm,
            verbose=True,
            prefix_messages=prefix_messages
        )

    def process_segment(self, existing_summary: str, new_transcript: str) -> str:
        """Process a new transcript segment and update the summary"""
        prompt = (
            f"Existing Summary:\n{existing_summary or 'No existing summary.'}\n\n"
            f"New Transcript Segment:\n{new_transcript}\n\n"
            "Please provide an updated summary incorporating the new information."
        )

        response = self.agent.chat(prompt)
        return response.response
class EmailQueryAgent:
    def __init__(self, llm_provider: str = "openai", api_key: Optional[str] = None):
        """Initialize email query agent"""
        self.llm = self._initialize_llm(llm_provider, api_key)
        self.email_service = EmailService()
        self.agent = self._initialize_agent()

    def _initialize_llm(self, provider: str, api_key: Optional[str] = None) -> LLM:
        """Initialize the chosen LLM provider"""
        if provider == "openai":
            api_key = api_key or os.getenv("OPENAI_API_KEY")
            if not api_key:
                raise ValueError("OpenAI API key must be provided")
            return OpenAI(
                model="gpt-4o-mini",
                api_key=api_key,
                temperature=0.1
            )
        elif provider == "anthropic":
            api_key = api_key or os.getenv("ANTHROPIC_API_KEY")
            if not api_key:
                raise ValueError("Anthropic API key must be provided")
            return Anthropic(
                model="claude-3-5-sonnet-20241022",
                api_key=api_key
            )
        else:
            raise ValueError(f"Unsupported LLM provider: {provider}")

    def _initialize_agent(self) -> FunctionCallingAgent:
        """Initialize the agent with email search prompts"""
        prefix_messages = [
            ChatMessage(
                role="system",
                content=(
                    "You are an AI assistant that helps find emails by creating Gmail search queries. "
                    "Given a conversation snippet, create a simple Gmail query. "
                    "\n\nRules:"
                    "\n- If someone mentions an email from a person, use 'from:person'"
                    "\n- If they mention a subject, add 'subject:topic'"
                    "\n- Keep queries simple and direct"
                    "\n- Return ONLY the query string, no other text"
                )
            )
        ]
        
        return FunctionCallingAgent.from_tools(
            tools=[],
            llm=self.llm,
            verbose=True,
            prefix_messages=prefix_messages
        )

    async def analyze_transcript_segment(self, transcript: str) -> Dict[str, Any]:
        """Find relevant email from transcript segment"""
        try:
            # Generate simple search query
            response = self.agent.chat(transcript)
            query = response.response.strip()
            
            # Search emails using query
            results = await self.email_service.search_emails([query])
            
            if results and len(results) > 0:
                return {
                    'status': 'success',
                    'query_used': query,
                    'email_found': results[0]
                }
            else:
                return {
                    'status': 'no_results',
                    'query_used': query
                }
                
        except Exception as e:
            return {
                'status': 'error',
                'error': str(e)
            }

================
File: .gitignore
================
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
env/
venv/
.env
*.pyc

# IDE
.vscode/
.idea/
*.swp
*.swo

# OS
.DS_Store
Thumbs.db

# Distribution / packaging
dist/
build/
*.egg-info/

# Virtual environment
venv/
env/
ENV/

.credentials

================
File: README.md
================
# ConveneAI
Intelligent meeting tool that works with your data


## Backend Setup
# ConveneAI Backend

Backend service that processes meeting transcripts to generate relevant email queries.

## Setup

### 1. Create Conda Environment

```bash
# Create environment
conda create -n meeting-assistant python=3.10
conda activate meeting-assistant
```

### 2. Install Dependencies

```bash
# Add required packages
pip install requirements.txt
```

### 3. Environment Variables

Create `.env` file in project root:
```env
OPENAI_API_KEY=
FLASK_ENV=development
FLASK_DEBUG=1
ANTHROPIC_API_KEY=
```

## Running the Server

```bash
# From project root
python backend/run.py
```

Server runs on `http://localhost:5000`

## Testing the Endpoints

### 1. Health Check
```bash
curl http://localhost:5000/health
```

### 2. Test with Sample Data
```bash
curl http://localhost:5000/demo-queries
```

### 3. Test with Custom Transcript
```bash
curl -X POST http://localhost:5000/analyze-transcript \
  -H "Content-Type: application/json" \
  -d '{
    "transcript": "John: Can you find that budget email from Sarah? Mary: The one from last week with the Excel file?"
  }'
````

================
File: requirements.txt
================
asgiref                            3.8.1
llama-index-core                   0.11.21
llama-index-llms-anthropic         0.3.8
llama-index-llms-openai            0.2.16
openai                             1.53.0
python-dotenv                      1.0.1
google-auth-oauthlib
google-api-python-client

================
File: setup.py
================
import os
import sys
from pathlib import Path

def check_dependencies():
    """Check if all required packages are installed"""
    required_packages = [
        'flask',
        'python-dotenv',
        'hypercorn',
        'asgiref',
        'llama-index-llms-anthropic'
    ]
    
    missing_packages = []
    for package in required_packages:
        try:
            __import__(package.replace('-', '_'))
        except ImportError:
            missing_packages.append(package)
    
    if missing_packages:
        print("Missing required packages. Installing...")
        os.system(f"pip install {' '.join(missing_packages)}")
    else:
        print("All required packages are installed.")

def check_env_file():
    """Check if .env file exists and has required variables"""
    env_path = Path('.env')
    
    if not env_path.exists():
        print("Creating .env file...")
        with open(env_path, 'w') as f:
            f.write("ANTHROPIC_API_KEY=your_key_here\n")
        print("Please edit .env file and add your Anthropic API key")
        return False
    
    return True

def check_directory_structure():
    """Check if all required directories and files exist"""
    required_structure = {
        'backend/app': ['__init__.py', 'routes.py'],
        'backend/config': ['__init__.py'],
        'backend': ['run.py'],
        'src/services': ['email_service.py'],
        'src/utils': ['query_generator.py'],
        'src': ['agent.py']
    }
    
    missing_items = []
    for directory, files in required_structure.items():
        dir_path = Path(directory)
        if not dir_path.exists():
            missing_items.append(f"Directory: {directory}")
            continue
        
        for file in files:
            file_path = dir_path / file
            if not file_path.exists():
                missing_items.append(f"File: {directory}/{file}")
    
    return missing_items

def main():
    """Main setup function"""
    print("Starting setup...")
    
    # Check dependencies
    check_dependencies()
    
    # Check directory structure
    missing_items = check_directory_structure()
    if missing_items:
        print("\nMissing required files/directories:")
        for item in missing_items:
            print(f"- {item}")
        print("\nPlease ensure all required files are present before running the application.")
        sys.exit(1)
    
    # Check .env file
    if not check_env_file():
        print("Please add your Anthropic API key to the .env file before running the application.")
        sys.exit(1)
    
    print("\nSetup complete! You can now run the application with:")
    print("python backend/run.py")

if __name__ == "__main__":
    main()
